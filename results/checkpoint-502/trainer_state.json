{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.0,
  "eval_steps": 500,
  "global_step": 502,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.03992015968063872,
      "grad_norm": 22.044357299804688,
      "learning_rate": 4.910358565737052e-05,
      "loss": 3.6294,
      "step": 10
    },
    {
      "epoch": 0.07984031936127745,
      "grad_norm": 23.671489715576172,
      "learning_rate": 4.8107569721115545e-05,
      "loss": 3.2495,
      "step": 20
    },
    {
      "epoch": 0.11976047904191617,
      "grad_norm": 23.55224609375,
      "learning_rate": 4.711155378486056e-05,
      "loss": 2.9875,
      "step": 30
    },
    {
      "epoch": 0.1596806387225549,
      "grad_norm": 22.363563537597656,
      "learning_rate": 4.611553784860558e-05,
      "loss": 2.8807,
      "step": 40
    },
    {
      "epoch": 0.1996007984031936,
      "grad_norm": 22.975242614746094,
      "learning_rate": 4.51195219123506e-05,
      "loss": 2.7783,
      "step": 50
    },
    {
      "epoch": 0.23952095808383234,
      "grad_norm": 21.77556800842285,
      "learning_rate": 4.412350597609562e-05,
      "loss": 2.9081,
      "step": 60
    },
    {
      "epoch": 0.27944111776447106,
      "grad_norm": 23.344886779785156,
      "learning_rate": 4.312749003984064e-05,
      "loss": 2.8326,
      "step": 70
    },
    {
      "epoch": 0.3193612774451098,
      "grad_norm": 22.17371940612793,
      "learning_rate": 4.213147410358566e-05,
      "loss": 2.7085,
      "step": 80
    },
    {
      "epoch": 0.3592814371257485,
      "grad_norm": 21.20341682434082,
      "learning_rate": 4.113545816733068e-05,
      "loss": 2.7814,
      "step": 90
    },
    {
      "epoch": 0.3992015968063872,
      "grad_norm": 20.147470474243164,
      "learning_rate": 4.0139442231075696e-05,
      "loss": 2.814,
      "step": 100
    },
    {
      "epoch": 0.43912175648702595,
      "grad_norm": 18.88545036315918,
      "learning_rate": 3.914342629482072e-05,
      "loss": 2.6961,
      "step": 110
    },
    {
      "epoch": 0.47904191616766467,
      "grad_norm": 22.435779571533203,
      "learning_rate": 3.814741035856574e-05,
      "loss": 2.731,
      "step": 120
    },
    {
      "epoch": 0.5189620758483033,
      "grad_norm": 19.0861873626709,
      "learning_rate": 3.715139442231076e-05,
      "loss": 2.6754,
      "step": 130
    },
    {
      "epoch": 0.5588822355289421,
      "grad_norm": 19.62987518310547,
      "learning_rate": 3.615537848605578e-05,
      "loss": 2.7953,
      "step": 140
    },
    {
      "epoch": 0.5988023952095808,
      "grad_norm": 15.572270393371582,
      "learning_rate": 3.51593625498008e-05,
      "loss": 2.5966,
      "step": 150
    },
    {
      "epoch": 0.6387225548902196,
      "grad_norm": 15.81411075592041,
      "learning_rate": 3.416334661354581e-05,
      "loss": 2.7123,
      "step": 160
    },
    {
      "epoch": 0.6786427145708582,
      "grad_norm": 15.445541381835938,
      "learning_rate": 3.316733067729084e-05,
      "loss": 2.7007,
      "step": 170
    },
    {
      "epoch": 0.718562874251497,
      "grad_norm": 16.246313095092773,
      "learning_rate": 3.217131474103586e-05,
      "loss": 2.69,
      "step": 180
    },
    {
      "epoch": 0.7584830339321357,
      "grad_norm": 15.982014656066895,
      "learning_rate": 3.117529880478088e-05,
      "loss": 2.8269,
      "step": 190
    },
    {
      "epoch": 0.7984031936127745,
      "grad_norm": 16.52667999267578,
      "learning_rate": 3.01792828685259e-05,
      "loss": 2.7549,
      "step": 200
    },
    {
      "epoch": 0.8383233532934131,
      "grad_norm": 17.06740379333496,
      "learning_rate": 2.918326693227092e-05,
      "loss": 2.6546,
      "step": 210
    },
    {
      "epoch": 0.8782435129740519,
      "grad_norm": 16.92047691345215,
      "learning_rate": 2.818725099601594e-05,
      "loss": 2.7087,
      "step": 220
    },
    {
      "epoch": 0.9181636726546906,
      "grad_norm": 15.673185348510742,
      "learning_rate": 2.7191235059760957e-05,
      "loss": 2.6158,
      "step": 230
    },
    {
      "epoch": 0.9580838323353293,
      "grad_norm": 15.661744117736816,
      "learning_rate": 2.6195219123505977e-05,
      "loss": 2.7084,
      "step": 240
    },
    {
      "epoch": 0.998003992015968,
      "grad_norm": 17.686098098754883,
      "learning_rate": 2.5199203187250998e-05,
      "loss": 2.7611,
      "step": 250
    },
    {
      "epoch": 1.035928143712575,
      "grad_norm": 14.870193481445312,
      "learning_rate": 2.420318725099602e-05,
      "loss": 2.2808,
      "step": 260
    },
    {
      "epoch": 1.0758483033932136,
      "grad_norm": 15.998302459716797,
      "learning_rate": 2.3207171314741035e-05,
      "loss": 2.2074,
      "step": 270
    },
    {
      "epoch": 1.1157684630738522,
      "grad_norm": 17.904296875,
      "learning_rate": 2.2211155378486056e-05,
      "loss": 2.1709,
      "step": 280
    },
    {
      "epoch": 1.1556886227544911,
      "grad_norm": 15.337933540344238,
      "learning_rate": 2.1215139442231077e-05,
      "loss": 2.2278,
      "step": 290
    },
    {
      "epoch": 1.1956087824351298,
      "grad_norm": 16.422977447509766,
      "learning_rate": 2.0219123505976094e-05,
      "loss": 2.1438,
      "step": 300
    },
    {
      "epoch": 1.2355289421157685,
      "grad_norm": 17.650041580200195,
      "learning_rate": 1.9223107569721114e-05,
      "loss": 2.1483,
      "step": 310
    },
    {
      "epoch": 1.2754491017964071,
      "grad_norm": 16.284709930419922,
      "learning_rate": 1.8227091633466138e-05,
      "loss": 2.1757,
      "step": 320
    },
    {
      "epoch": 1.3153692614770458,
      "grad_norm": 14.679665565490723,
      "learning_rate": 1.723107569721116e-05,
      "loss": 2.1568,
      "step": 330
    },
    {
      "epoch": 1.3552894211576847,
      "grad_norm": 17.088802337646484,
      "learning_rate": 1.6235059760956176e-05,
      "loss": 2.1108,
      "step": 340
    },
    {
      "epoch": 1.3952095808383234,
      "grad_norm": 14.845199584960938,
      "learning_rate": 1.5239043824701197e-05,
      "loss": 2.2104,
      "step": 350
    },
    {
      "epoch": 1.435129740518962,
      "grad_norm": 18.459043502807617,
      "learning_rate": 1.4243027888446217e-05,
      "loss": 2.2111,
      "step": 360
    },
    {
      "epoch": 1.475049900199601,
      "grad_norm": 17.829586029052734,
      "learning_rate": 1.3247011952191234e-05,
      "loss": 2.2065,
      "step": 370
    },
    {
      "epoch": 1.5149700598802394,
      "grad_norm": 17.37154769897461,
      "learning_rate": 1.2250996015936257e-05,
      "loss": 2.229,
      "step": 380
    },
    {
      "epoch": 1.5548902195608783,
      "grad_norm": 16.563661575317383,
      "learning_rate": 1.1254980079681275e-05,
      "loss": 2.2464,
      "step": 390
    },
    {
      "epoch": 1.594810379241517,
      "grad_norm": 17.591636657714844,
      "learning_rate": 1.0258964143426296e-05,
      "loss": 2.3427,
      "step": 400
    },
    {
      "epoch": 1.6347305389221556,
      "grad_norm": 14.978331565856934,
      "learning_rate": 9.262948207171315e-06,
      "loss": 1.971,
      "step": 410
    },
    {
      "epoch": 1.6746506986027945,
      "grad_norm": 17.443605422973633,
      "learning_rate": 8.266932270916335e-06,
      "loss": 2.1295,
      "step": 420
    },
    {
      "epoch": 1.7145708582834331,
      "grad_norm": 18.1373291015625,
      "learning_rate": 7.270916334661355e-06,
      "loss": 2.2556,
      "step": 430
    },
    {
      "epoch": 1.7544910179640718,
      "grad_norm": 18.57560157775879,
      "learning_rate": 6.274900398406375e-06,
      "loss": 2.1833,
      "step": 440
    },
    {
      "epoch": 1.7944111776447107,
      "grad_norm": 17.74949836730957,
      "learning_rate": 5.278884462151395e-06,
      "loss": 2.2001,
      "step": 450
    },
    {
      "epoch": 1.8343313373253491,
      "grad_norm": 20.0343017578125,
      "learning_rate": 4.282868525896414e-06,
      "loss": 2.098,
      "step": 460
    },
    {
      "epoch": 1.874251497005988,
      "grad_norm": 14.378087997436523,
      "learning_rate": 3.2868525896414344e-06,
      "loss": 2.217,
      "step": 470
    },
    {
      "epoch": 1.9141716566866267,
      "grad_norm": 18.886547088623047,
      "learning_rate": 2.290836653386454e-06,
      "loss": 2.0638,
      "step": 480
    },
    {
      "epoch": 1.9540918163672654,
      "grad_norm": 18.212858200073242,
      "learning_rate": 1.2948207171314743e-06,
      "loss": 2.2342,
      "step": 490
    },
    {
      "epoch": 1.9940119760479043,
      "grad_norm": 17.232690811157227,
      "learning_rate": 2.9880478087649405e-07,
      "loss": 2.3009,
      "step": 500
    }
  ],
  "logging_steps": 10,
  "max_steps": 502,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 100,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 25567833600000.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
